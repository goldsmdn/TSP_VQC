{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d8c0802a-cb35-44c0-84f4-54fcf4ee9bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import ast\n",
    "import torch\n",
    "from classes.MyModel import MyModel\n",
    "\n",
    "from modules.helper_functions_tsp import (find_problem_size, \n",
    "                                          cost_fn_fact, \n",
    "                                          cost_fn_tensor,\n",
    "                                          read_index, \n",
    "                                          hot_start, \n",
    "                                          hot_start_list_to_string,\n",
    "                                          update_parameters_using_gradient, \n",
    "                                          define_parameters, \n",
    "                                          create_initial_rotations,\n",
    "                                          bind_weights, \n",
    "                                          vqc_circuit, \n",
    "                                          cost_func_evaluate, \n",
    "                                          find_run_stats,\n",
    "                                          find_distances_array,\n",
    "                                          format_boolean,\n",
    "                                          )\n",
    "\n",
    "from modules.helper_ML_functions import (find_device, \n",
    "                                         get_ready_to_train,\n",
    "                                         train_model)\n",
    "\n",
    "from classes.DataLogger import DataLogger, SubDataLogger\n",
    "\n",
    "import copy\n",
    "import time\n",
    "from pathlib import Path\n",
    "\n",
    "from modules.config import(CONTROL_DIR, \n",
    "                           CONTROL_FILE, \n",
    "                           ENCODING, \n",
    "                           CACHE_MAX_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49cadc20",
   "metadata": {},
   "source": [
    "Load control data and instantiate data logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c74ef82e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading control data from control\\control_parameters.csv\n",
      "{0: {'quantum': 'FALSE', 'locations': '5', 'slice': '1', 'shots': '64', 'layers': '2', 'std_dev': '0.5', 'mode': ' ', 'iterations': '50', 'gray': 'TRUE', 'hot_start': 'TRUE', 'gradient_type': 'SGD', 'formulation': 'new', 'lr': '0.0001', 'weight_decay': '0.0002', 'momentum': '0', 'alpha': ' ', 'big_a': ' ', 'c': ' ', 'eta': ' ', 'gamma': ' ', 's': ' ', 'print_frequency': ' '}, 1: {'quantum': 'TRUE', 'locations': '5', 'slice': '1', 'shots': '1024', 'layers': ' ', 'std_dev': ' ', 'mode': '2', 'iterations': '50', 'gray': 'FALSE', 'hot_start': 'FALSE', 'gradient_type': 'SPSA', 'formulation': 'new', 'lr': '', 'weight_decay': '', 'momentum': '', 'alpha': '0.602', 'big_a': '50', 'c': '0.314', 'eta': '0.02', 'gamma': '0.101', 's': '0.5', 'print_frequency': '50'}}\n",
      "Data logger instantiated.  Run ID: 20250321-13-57-56\n"
     ]
    }
   ],
   "source": [
    "control_path = Path(CONTROL_DIR).joinpath(CONTROL_FILE)\n",
    "control_dict = read_index(control_path, ENCODING)\n",
    "print(f'Reading control data from {control_path}')\n",
    "print(control_dict)\n",
    "datalogger = DataLogger()\n",
    "EMPTY = ' '"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b78bc765",
   "metadata": {},
   "source": [
    "## Main loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29fbde3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data logger instantiated.  Run ID: 20250321-13-57-56\n",
      "SubDataLogger instantiated.  Run ID = 20250321-13-57-56 - 13-57-56\n",
      "results are written to the results folder\n",
      "Reading distance data\n",
      "Data for Run ID: 20250321-13-57-56 - 13-57-56 successfully added to results\\results.csv\n",
      "Data logger instantiated.  Run ID: 20250321-13-58-11\n",
      "SubDataLogger instantiated.  Run ID = 20250321-13-57-56 - 13-58-11\n",
      "results are written to the results folder\n",
      "Reading distance data\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'eta' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 110\u001b[0m\n\u001b[0;32m    102\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m quantum:\n\u001b[0;32m    103\u001b[0m     rots \u001b[38;5;241m=\u001b[39m copy\u001b[38;5;241m.\u001b[39mdeepcopy(init_rots)\n\u001b[0;32m    105\u001b[0m     index_list, sliced_list, lowest_list, _ , average_list, _ \u001b[38;5;241m=\u001b[39m \\\n\u001b[0;32m    106\u001b[0m     update_parameters_using_gradient(locations\u001b[38;5;241m=\u001b[39mlocations, iterations\u001b[38;5;241m=\u001b[39miterations, \n\u001b[0;32m    107\u001b[0m                                     print_frequency\u001b[38;5;241m=\u001b[39mprint_frequency, params\u001b[38;5;241m=\u001b[39mparams,\n\u001b[0;32m    108\u001b[0m                                     rots\u001b[38;5;241m=\u001b[39mrots,  \n\u001b[0;32m    109\u001b[0m                                     cost_fn\u001b[38;5;241m=\u001b[39mcost_fn, qc \u001b[38;5;241m=\u001b[39m qc, shots\u001b[38;5;241m=\u001b[39mshots, s\u001b[38;5;241m=\u001b[39ms, \n\u001b[1;32m--> 110\u001b[0m                                     eta\u001b[38;5;241m=\u001b[39m\u001b[43meta\u001b[49m, average_slice\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mslice\u001b[39m, gray\u001b[38;5;241m=\u001b[39mgray, \n\u001b[0;32m    111\u001b[0m                                     verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, gradient_type\u001b[38;5;241m=\u001b[39mgradient_type,\n\u001b[0;32m    112\u001b[0m                                     alpha\u001b[38;5;241m=\u001b[39malpha, gamma\u001b[38;5;241m=\u001b[39mgamma, c\u001b[38;5;241m=\u001b[39mc,\n\u001b[0;32m    113\u001b[0m                                     big_a\u001b[38;5;241m=\u001b[39mbig_a,\n\u001b[0;32m    114\u001b[0m                                     method\u001b[38;5;241m=\u001b[39mformulation,\n\u001b[0;32m    115\u001b[0m                                     print_results\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    116\u001b[0m             )\n\u001b[0;32m    117\u001b[0m     av_cost_list_all\u001b[38;5;241m.\u001b[39mappend(average_list)\n\u001b[0;32m    118\u001b[0m     lowest_list_all\u001b[38;5;241m.\u001b[39mappend(lowest_list) \n",
      "\u001b[1;31mNameError\u001b[0m: name 'eta' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "for keys, control_items in control_dict.items():\n",
    "    subdatalogger = SubDataLogger(datalogger)\n",
    "    data_dict = dict(control_items)\n",
    "    quantum = format_boolean(data_dict['quantum'])\n",
    "    locations = int(data_dict['locations'])\n",
    "    slice = float(data_dict['slice'])\n",
    "    shots = int(data_dict['shots'])\n",
    "    iterations = int(data_dict['iterations'])\n",
    "    gray = format_boolean(data_dict['gray'])\n",
    "    hot_start_bool = format_boolean(data_dict['hot_start'])\n",
    "    gradient_type = data_dict['gradient_type']\n",
    "    formulation = data_dict['formulation']\n",
    "    if not quantum:\n",
    "        layers = int(data_dict['layers'])\n",
    "        std_dev = float(data_dict['std_dev'])\n",
    "        lr = float(data_dict['lr'])\n",
    "        weight_decay = float(data_dict['weight_decay'])\n",
    "        momentum = float(data_dict['momentum'])\n",
    "    if quantum:\n",
    "        mode = int(data_dict['mode'])\n",
    "        alpha = float(data_dict['alpha'])\n",
    "        big_a = float(data_dict['big_a'])\n",
    "        c = float(data_dict['c'])\n",
    "        gamma = float(data_dict['gamma'])\n",
    "        eta = float(data_dict['eta'])\n",
    "        s = float(data_dict['s'])\n",
    "        print_frequency = int(data_dict['print_frequency'])\n",
    "\n",
    "    data_dict['runid'] = datalogger.runid\n",
    "    data_dict['subid'] = subdatalogger.subid\n",
    "    data_dict['cache_max_size'] = CACHE_MAX_SIZE\n",
    "    qubits = find_problem_size(locations, formulation)\n",
    "    data_dict['qubits'] = qubits\n",
    "    distance_array, best_dist = find_distances_array(locations, print_comments=False)\n",
    "    data_dict['best_dist'] = best_dist  \n",
    "    \n",
    "    if quantum:\n",
    "    #Define the VQC circuits with appropriate parameters\n",
    "        params = define_parameters(qubits, mode)\n",
    "        qc = vqc_circuit(qubits, params, mode)\n",
    "    else:\n",
    "        device = find_device()\n",
    "\n",
    "    #define the cost function for this run\n",
    "    cost_fn = cost_fn_fact(locations,distance_array, gray, method = formulation)\n",
    "\n",
    "    #print(hot_start_bool)\n",
    "\n",
    "    if hot_start_bool:\n",
    "        hot_start_list = hot_start(distance_array, locations)\n",
    "        bin_hot_start_list =  hot_start_list_to_string(hot_start_list, \n",
    "                                                       locations, \n",
    "                                                       gray, \n",
    "                                                       formulation\n",
    "                                                       )\n",
    "        hot_start_dist = cost_fn(bin_hot_start_list)\n",
    "        if quantum:\n",
    "            init_rots = create_initial_rotations(qubits, \n",
    "                                                 mode, \n",
    "                                                 bin_hot_start_list,\n",
    "                                                 hot_start=True\n",
    "                                                 )\n",
    "        else:\n",
    "            bin_hot_start_list_tensor = torch.tensor([bin_hot_start_list])\n",
    "            unrepeated_input = bin_hot_start_list_tensor.float().to(device)\n",
    "            my_input = unrepeated_input.repeat(shots, 1).requires_grad_(True)\n",
    "            \n",
    "    else:\n",
    "        if quantum:\n",
    "            init_rots = create_initial_rotations(qubits, mode)\n",
    "        else:\n",
    "            unrepeated_input = torch.full((shots,1), 0.5).float().to(device)\n",
    "            my_input = unrepeated_input.repeat(shots, 1).requires_grad_(True)\n",
    "\n",
    "    if quantum:\n",
    "        bc = bind_weights(params, init_rots, qc)\n",
    "        bc.measure_all()\n",
    "    else:\n",
    "        model = MyModel(qubits, layers, std_dev, cost_fn).to(device)\n",
    "\n",
    "    if hot_start_bool:\n",
    "    # find hot start distance\n",
    "        if quantum:\n",
    "            hot_start_dist, _, _ = cost_func_evaluate(cost_fn, bc, shots=shots, average_slice=slice)\n",
    "        else:\n",
    "            distance_tensor = cost_fn_tensor(bin_hot_start_list_tensor, \n",
    "                                             cost_fn\n",
    "                                             ).clone().detach().requires_grad_(True)\n",
    "            hot_start_dist = float(distance_tensor)\n",
    "\n",
    "        data_dict['hot_start_dist'] = hot_start_dist\n",
    "    else:\n",
    "        data_dict['hot_start_dist'] = 'n/a'\n",
    "\n",
    "    t0 = time.time()\n",
    "    av_cost_list_all, lowest_list_all, sliced_cost_list_all = [], [], []\n",
    "\n",
    "    if quantum:\n",
    "        rots = copy.deepcopy(init_rots)\n",
    "        \n",
    "        index_list, sliced_list, lowest_list, _ , average_list, _ = \\\n",
    "        update_parameters_using_gradient(locations=locations, iterations=iterations, \n",
    "                                        print_frequency=print_frequency, params=params,\n",
    "                                        rots=rots,  \n",
    "                                        cost_fn=cost_fn, qc = qc, shots=shots, s=s, \n",
    "                                        eta=eta, average_slice=slice, gray=gray, \n",
    "                                        verbose=False, gradient_type=gradient_type,\n",
    "                                        alpha=alpha, gamma=gamma, c=c,\n",
    "                                        big_a=big_a,\n",
    "                                        method=formulation,\n",
    "                                        print_results=False\n",
    "                )\n",
    "        av_cost_list_all.append(average_list)\n",
    "        lowest_list_all.append(lowest_list) \n",
    "        sliced_cost_list_all.append(sliced_list)\n",
    "        best_dist_found, iteration_found = find_run_stats(lowest_list)\n",
    "        data_dict['best_dist_found'] = best_dist_found\n",
    "        data_dict['iteration_found'] = iteration_found\n",
    "    else:\n",
    "        target, criterion, optimizer = get_ready_to_train(model, \n",
    "                                                          optimizer=gradient_type, \n",
    "                                                          lr=lr, \n",
    "                                                          weight_decay=weight_decay, \n",
    "                                                          momentum=momentum\n",
    "                                                          )\n",
    "        lowest_cost, epoch_lowest_cost, _, _ = train_model(iterations,\n",
    "                                                                    model, \n",
    "                                                                    my_input, \n",
    "                                                                    target, \n",
    "                                                                    criterion,\n",
    "                                                                    optimizer,\n",
    "                                                                    )\n",
    "        data_dict['best_dist_found'] = lowest_cost\n",
    "        data_dict['iteration_found'] = epoch_lowest_cost\n",
    "     \n",
    "        \n",
    "    t1 = time.time()\n",
    "    elapsed = t1-t0\n",
    "    data_dict['elapsed'] = elapsed\n",
    "\n",
    "    items, hits, misses = cost_fn.report_cache_stats()\n",
    "    data_dict['cache_items'] = items\n",
    "    data_dict['cache_hits'] = hits\n",
    "    data_dict['cache_misses'] = misses\n",
    "\n",
    "    cost_fn.clear_cache() #need to clear cache so statistics are not cumulative\n",
    "    \n",
    "    subdatalogger.save_dict_to_csv(data_dict) # don't write header\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cwq3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
