{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d8c0802a-cb35-44c0-84f4-54fcf4ee9bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from modules.helper_functions_tsp import ( \n",
    "    read_file_name, validate_distance_array, find_problem_size, cost_fn_fact, \n",
    "    read_index, hot_start, hot_start_list_to_string,\n",
    "    update_parameters_using_gradient, define_parameters, create_initial_rotations,\n",
    "    bind_weights, vqc_circuit, cost_func_evaluate, find_run_stats)\n",
    "from classes.DataLogger import DataLogger, SubDataLogger\n",
    "\n",
    "import copy\n",
    "import time\n",
    "\n",
    "from modules.config import(CONTROL_FILE, ENCODING,\n",
    "                           DATA_SOURCES, CACHE_MAX_SIZE\n",
    "                           )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49cadc20",
   "metadata": {},
   "source": [
    "Load control data and instantiate data logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c74ef82e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: {'locations': '4', 'slice': '1', 'shots': '1024', 'mode': '2', 'iterations': '50', 'gray': 'True', 'hot_start': 'True', 'gradient_type': 'SPSA', 'formulation': 'new', 'alpha': '0.602', 'big_a': '50', 'c': '0.314', 'eta': '0.02', 'gamma': '0.101', 's': '0.5', 'print_frequency': '50'}, 1: {'locations': '4', 'slice': '1', 'shots': '1024', 'mode': '2', 'iterations': '50', 'gray': 'False', 'hot_start': 'True', 'gradient_type': 'SPSA', 'formulation': 'new', 'alpha': '0.602', 'big_a': '50', 'c': '0.314', 'eta': '0.02', 'gamma': '0.101', 's': '0.5', 'print_frequency': '50'}}\n",
      "Data logger instantiated.  Run ID: 20250216-14-01-36\n"
     ]
    }
   ],
   "source": [
    "control_dict = read_index(CONTROL_FILE, ENCODING)\n",
    "print(control_dict)\n",
    "datalogger = DataLogger()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b78bc765",
   "metadata": {},
   "source": [
    "## Main loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29fbde3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data logger instantiated.  Run ID: 20250216-14-01-36\n",
      "SubDataLogger instantiated.  Run ID = 20250216-14-01-36 - 14-01-36\n",
      "Folder data_sub_path = data\\20250216-14-01-36 is used for data writing\n",
      "Data will be added to file = data\\20250216-14-01-36\\20250216-14-01-36.csv\n",
      "Data will be read from filename networks/four_d.txt.  It is known that the shortest distance is 21.\n",
      "For iteration 0 using the best 100.0 percent of the results\n",
      "The average cost from the sample is 21.000 and the top-sliced average of the best results is 21.000\n",
      "The lowest cost from the sample is 21.000\n",
      "The lowest cost to date is 21.000 corresponding to bit string [0, 0, 0, 0, 0] \n",
      "and route [0, 1, 2, 3]\n",
      "self.header_written = False\n",
      "Writing header. self.header_written = False\n",
      "Writen header. self.header_written = False\n",
      "Writing row. self.header_written = False\n",
      "Data_dict = {'locations': '4', 'slice': '1', 'shots': '1024', 'mode': '2', 'iterations': '50', 'gray': 'True', 'hot_start': 'True', 'gradient_type': 'SPSA', 'formulation': 'new', 'alpha': '0.602', 'big_a': '50', 'c': '0.314', 'eta': '0.02', 'gamma': '0.101', 's': '0.5', 'print_frequency': '50', 'runid': '20250216-14-01-36', 'subid': '14-01-36', 'cache_max_size': 500000, 'best_dist': 21, 'hot_start_dist': np.float64(21.0), 'hot_start_cost': np.float64(21.0), 'best_dist_found': np.float64(21.0), 'iteration_found': 0, 'elapsed': 2.4174914360046387, 'cache_items': 31, 'cache_hits': 1666, 'cache_misses': 31}\n",
      "Data for Run ID: 20250216-14-01-36 - 14-01-36 successfully added to data\\20250216-14-01-36\\20250216-14-01-36.csv\n",
      "Data logger instantiated.  Run ID: 20250216-14-01-38\n",
      "SubDataLogger instantiated.  Run ID = 20250216-14-01-36 - 14-01-38\n",
      "Folder data_sub_path = data\\20250216-14-01-36 is used for data writing\n",
      "Data will be added to file = data\\20250216-14-01-36\\20250216-14-01-36.csv\n",
      "Data will be read from filename networks/four_d.txt.  It is known that the shortest distance is 21.\n",
      "For iteration 0 using the best 100.0 percent of the results\n",
      "The average cost from the sample is 21.000 and the top-sliced average of the best results is 21.000\n",
      "The lowest cost from the sample is 21.000\n",
      "The lowest cost to date is 21.000 corresponding to bit string [0, 0, 0, 0, 0] \n",
      "and route [0, 1, 2, 3]\n",
      "self.header_written = False\n",
      "Writing row. self.header_written = False\n",
      "Data_dict = {'locations': '4', 'slice': '1', 'shots': '1024', 'mode': '2', 'iterations': '50', 'gray': 'False', 'hot_start': 'True', 'gradient_type': 'SPSA', 'formulation': 'new', 'alpha': '0.602', 'big_a': '50', 'c': '0.314', 'eta': '0.02', 'gamma': '0.101', 's': '0.5', 'print_frequency': '50', 'runid': '20250216-14-01-36', 'subid': '14-01-38', 'cache_max_size': 500000, 'best_dist': 21, 'hot_start_dist': np.float64(21.0), 'hot_start_cost': np.float64(21.0), 'best_dist_found': np.float64(21.0), 'iteration_found': 0, 'elapsed': 2.2494473457336426, 'cache_items': 32, 'cache_hits': 2086, 'cache_misses': 32}\n",
      "Data for Run ID: 20250216-14-01-36 - 14-01-38 successfully added to data\\20250216-14-01-36\\20250216-14-01-36.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for keys, control_items in control_dict.items():\n",
    "    subdatalogger = SubDataLogger(datalogger)\n",
    "    data_dict = dict(control_items)\n",
    "\n",
    "    locations = int(data_dict['locations'])\n",
    "    slice = float(data_dict['slice'])\n",
    "    shots = int(data_dict['shots'])\n",
    "    mode = int(data_dict['mode'])\n",
    "    iterations = int(data_dict['iterations'])\n",
    "    gray = bool(data_dict['gray'])\n",
    "    hot_start_bool = bool(data_dict['hot_start'])\n",
    "    gradient_type = data_dict['gradient_type']\n",
    "    formulation = data_dict['formulation']\n",
    "    alpha = float(data_dict['alpha'])\n",
    "    big_a = float(data_dict['big_a'])\n",
    "    c = float(data_dict['c'])\n",
    "    eta = float(data_dict['eta'])\n",
    "    gamma = float(data_dict['gamma'])\n",
    "    s = float(data_dict['s'])\n",
    "    print_frequency = int(data_dict['print_frequency'])\n",
    "\n",
    "    data_dict['runid'] = datalogger.runid\n",
    "    data_dict['subid'] = subdatalogger.subid\n",
    "    data_dict['cache_max_size'] = CACHE_MAX_SIZE\n",
    "\n",
    "    qubits = find_problem_size(locations, formulation)\n",
    "    data_filename = read_file_name(locations, DATA_SOURCES)\n",
    "    #Data sources are held locally to avoid downstream dependencies.  \n",
    "    #Read the data, and print out the filename and best distance held in the data.\n",
    "    best_dist = DATA_SOURCES[locations]['best']\n",
    "    data_dict['best_dist'] = best_dist\n",
    "    print(f'Data will be read from filename {data_filename}.  It is known that the shortest distance is {best_dist}.')\n",
    "    #Read and validate the distance array.  This checks the array is the correct shape, and is symmetric.\n",
    "    distance_array = np.genfromtxt(data_filename)\n",
    "    validate_distance_array(distance_array, locations)\n",
    "    #Define the VQC circuits with appropriate parameters\n",
    "    params = define_parameters(qubits, mode)\n",
    "    #define the cost function for this run\n",
    "    qc = vqc_circuit(qubits, params, mode)\n",
    "    cost_fn = cost_fn_fact(locations,distance_array, gray, method = formulation)\n",
    "\n",
    "    if hot_start_bool:\n",
    "        hot_start_list = hot_start(distance_array, locations)\n",
    "        bin_hot_start_list =  hot_start_list_to_string(hot_start_list, locations, gray, formulation)\n",
    "        hot_start_dist = cost_fn(bin_hot_start_list)\n",
    "        data_dict['hot_start_dist'] = hot_start_dist\n",
    "        init_rots = create_initial_rotations(qubits, mode, bin_hot_start_list, hot_start=True)\n",
    "    else:\n",
    "        init_rots = create_initial_rotations(qubits, mode)\n",
    "\n",
    "    bc = bind_weights(params, init_rots, qc)\n",
    "    bc.measure_all()\n",
    "\n",
    "    if hot_start_bool:\n",
    "        hot_start_cost, _, _ = cost_func_evaluate(cost_fn, bc, shots=shots, average_slice=slice)\n",
    "        data_dict['hot_start_cost'] = hot_start_cost\n",
    "\n",
    "    t0 = time.time()\n",
    "    av_cost_list_all, lowest_list_all, sliced_cost_list_all = [], [], []\n",
    "    rots = copy.deepcopy(init_rots)\n",
    "    \n",
    "    index_list, sliced_list, lowest_list, _ , average_list, _ = \\\n",
    "    update_parameters_using_gradient(locations=locations, iterations=iterations, \n",
    "                                    print_frequency=print_frequency, params=params,\n",
    "                                    rots=rots,  \n",
    "                                    cost_fn=cost_fn, qc = qc, shots=shots, s=s, \n",
    "                                    eta=eta, average_slice=slice, gray=gray, \n",
    "                                    verbose=False, gradient_type=gradient_type,\n",
    "                                    alpha=alpha, gamma=gamma, c=c,\n",
    "                                    big_a=big_a,\n",
    "                                    method=formulation,\n",
    "                                    print_results=False\n",
    "            )\n",
    "    av_cost_list_all.append(average_list)\n",
    "    lowest_list_all.append(lowest_list) \n",
    "    sliced_cost_list_all.append(sliced_list)\n",
    "    best_dist_found, iteration_found = find_run_stats(lowest_list)\n",
    "    data_dict['best_dist_found'] = best_dist_found\n",
    "    data_dict['iteration_found'] = iteration_found\n",
    "    t1 = time.time()\n",
    "    elapsed = t1-t0\n",
    "    data_dict['elapsed'] = elapsed\n",
    "\n",
    "    #print(type(cost_fn.report_cache_stats))\n",
    "    #items, hits, misses = cost_fn.report_cache_stats()\n",
    "    data_dict['cache_items'] = len(cost_fn.cache)\n",
    "    data_dict['cache_hits'] = cost_fn.cache_hits\n",
    "    data_dict['cache_misses'] = cost_fn.cache_misses\n",
    "\n",
    "    cost_fn.clear_cache() #need to clear cache so statistics are not cumulative\n",
    "    \n",
    "    subdatalogger.save_dict_to_csv(data_dict) # don't write header\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "79587e1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datalogger.header_written\n",
    "subdatalogger.header_written"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "29661952",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'runid': '20250216-14-01-36', 'header_written': True, 'fieldnames': ['runid', 'subid', 'locations', 'slice', 'shots', 'mode', 'iterations', 'gray', 'hot_start', 'gradient_type', 'formulation', 'alpha', 'big_a', 'c', 'eta', 'gamma', 's', 'print_frequency', 'cache_max_size', 'elapsed', 'hot_start_dist', 'hot_start_cost', 'best_dist_found', 'best_dist', 'iteration_found', 'cache_items', 'cache_hits', 'cache_misses']}\n",
      "{'runid': '20250216-14-01-36', 'header_written': False, 'fieldnames': ['runid', 'subid', 'locations', 'slice', 'shots', 'mode', 'iterations', 'gray', 'hot_start', 'gradient_type', 'formulation', 'alpha', 'big_a', 'c', 'eta', 'gamma', 's', 'print_frequency', 'cache_max_size', 'elapsed', 'hot_start_dist', 'hot_start_cost', 'best_dist_found', 'best_dist', 'iteration_found', 'cache_items', 'cache_hits', 'cache_misses'], 'parent': <classes.DataLogger.DataLogger object at 0x0000026883DD6180>, 'data_sub_path': WindowsPath('data/20250216-14-01-36'), 'subid': '14-01-38', 'filename': WindowsPath('data/20250216-14-01-36/20250216-14-01-36.csv'), 'full_id': '20250216-14-01-36 - 14-01-38'}\n"
     ]
    }
   ],
   "source": [
    "print(vars(datalogger))\n",
    "print(vars(subdatalogger))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cwq",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
