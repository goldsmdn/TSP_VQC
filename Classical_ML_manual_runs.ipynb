{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test of bespoke neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import necessary modules:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from classes.MyModel import MyModel\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import math as math\n",
    "from pathlib import Path\n",
    "from torchviz import make_dot\n",
    "\n",
    "from modules.helper_functions_tsp import (find_problem_size,\n",
    "                                          find_distances_array,\n",
    "                                          cost_fn_fact, \n",
    "                                          cost_fn_tensor, \n",
    "                                          hot_start, \n",
    "                                          hot_start_list_to_string)\n",
    "\n",
    "from modules.config import GRAPH_DIR\n",
    "from modules.helper_ML_functions import (find_device, \n",
    "                                         get_ready_to_train,\n",
    "                                         train_model)\n",
    "\n",
    "from modules.graph_functions import (plot_sine_activation,\n",
    "                                     plot_model_training)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up constants:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOCATIONS = 8                       #locations in problem\n",
    "DECODING_FORMULATION = 'original'   #decoding formulation\n",
    "                                    #options: 'original', 'new'\n",
    "GRAY = False                        #gray code  \n",
    "STD_DEV = 0.5                       #standard deviation for weight randomization\n",
    "NUM_EPOCHS = 50                     #number of epochs for training\n",
    "NUM_LAYERS = 2                      #number of layers in the mode\n",
    "LR = 0.0001                         #Learning rate\n",
    "VERBOSE = False                     #controls how much output the model produces\n",
    "SHOTS = 64                          #size of input tensor.  Reduces randomness\n",
    "MOMENTUM = 0.000                    #momentum for optimizer\n",
    "WEIGHT_DECAY = 0.0002               #importance of L2 regularization in optimiser\n",
    "OPTIMIZER = 'SGD'                   #optimizer to use\n",
    "                                    #options: 'Adam', 'SGD', 'RMSprop\n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in data, report on data read and validate distance array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance_array, best_dist = find_distances_array(LOCATIONS, print_comments=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate cost function and clear cache:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost_fn = cost_fn_fact(LOCATIONS, distance_array, GRAY, method = DECODING_FORMULATION, verbose=VERBOSE)\n",
    "cost_fn.clear_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if CUDA is available and set the device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = find_device()\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find problem size:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qubits = find_problem_size(LOCATIONS, DECODING_FORMULATION)\n",
    "print(f'There are {qubits} qubits needed for {LOCATIONS} locations in the {DECODING_FORMULATION} formulation.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find a hot start using a lazy classical algorithm and find the quality of the hot start:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hot_start_list = hot_start(distance_array, LOCATIONS)\n",
    "print(f'The hot start location list is {hot_start_list}')\n",
    "bin_hot_start_list =  hot_start_list_to_string(hot_start_list, LOCATIONS, GRAY, DECODING_FORMULATION)\n",
    "print(f'This is equivalent to a binary list: {bin_hot_start_list}')\n",
    "bin_hot_start_list_tensor = torch.tensor([bin_hot_start_list])\n",
    "print(f'bin_hot_start_list_tensor = {bin_hot_start_list_tensor}')\n",
    "distance_tensor = cost_fn_tensor(bin_hot_start_list_tensor, cost_fn).clone().detach().requires_grad_(True)\n",
    "print(f'The hot start distance is {float(distance_tensor):.2f}, compared to a best distance of {best_dist:.2f}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up input as repeated hot start tensor calculated above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unrepeated_input = bin_hot_start_list_tensor.float().to(device)\n",
    "my_input = unrepeated_input.repeat(SHOTS, 1).requires_grad_(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up model with gradient required:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = MyModel(qubits, NUM_LAYERS, STD_DEV, cost_fn).to(device)\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Report on model parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_params = sum(\n",
    "\tparam.numel() for param in model.parameters()\n",
    ")\n",
    "trainable_params = sum(\n",
    "\tp.numel() for p in model.parameters() if p.requires_grad\n",
    ")\n",
    "\n",
    "print(f'There are {total_params} parameters in total, of which {trainable_params} are trainable')\n",
    "\n",
    "for name, param in model.named_parameters():\n",
    "    print(f\"Parameter {name} requires_grad: {param.requires_grad}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test the Sine activation function and print out a graph:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the sine activation function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_sine_activation()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print out model details including graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model(my_input)\n",
    "lowest_cost = float(output)\n",
    "print(f'Output = {output}')\n",
    "filename = Path(GRAPH_DIR).joinpath('torchviz')\n",
    "\n",
    "param_dict = dict(model.named_parameters())\n",
    "print(param_dict)  # Debugging: print the parameters to ensure they seem reasonable\n",
    "make_dot(output, params=param_dict).render(filename, format=\"png\")\n",
    "make_dot(output, params=param_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up criterion, optimizer and target ready to train model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target, criterion, optimizer = get_ready_to_train(model, OPTIMIZER, LR, WEIGHT_DECAY, momentum = MOMENTUM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train model and print out results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lowest_cost, epoch_lowest_cost, epoch_hist, loss_hist, lowest_history = \\\n",
    "    train_model(NUM_EPOCHS,\n",
    "                model, \n",
    "                my_input, \n",
    "                target, \n",
    "                criterion,\n",
    "                optimizer,\n",
    "                print_results=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'The lowest cost found was {lowest_cost:.3f} at epoch {epoch_lowest_cost}.')\n",
    "print(f'The best known cost is {best_dist:.3f} and the hot start cost was {float(distance_tensor):.3f}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot loss ratio by epoch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model_training(epoch_hist, loss_hist)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print out parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in model.children():\n",
    "    if isinstance(layer, nn.Linear):\n",
    "        print('weight:', layer.weight)\n",
    "        print('bias:', layer.bias)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cwq3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
